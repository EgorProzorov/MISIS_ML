{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики эффективности моделей машинного обучения\n",
    "## Цель работы\n",
    "Научиться измерять эффективность моделей машинного обучения с помощью метрик, вибирать метрики исходя из задачи, разбивать датасет на обучающую и тестовую подвыборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание работы\n",
    "1. Загрузите данные о вероятности развития сердечного приступа, прилагающийся к этой работе (heart.csv).\n",
    "2. Обучите на этих данных простую модель логистической регрессии и выведите метрику точности (accuracy).\n",
    "3. Разделите датасет на две части - первую половину используйте для обучения, а вторую - для оценки точности. Сравните значения метрик.\n",
    "4. Разделите датасет на две части случайным образом. Повторите анализ.\n",
    "5. Разделите датасет с помощью библиотечной функции. Повторите анализ несколько раз.\n",
    "6. Постройте матрицу классификации и отчет о классификации для обученной модели для обучающей и тестовой выборок. Проинтерпретируйте полученные значения.\n",
    "7. Подсчитайте для построенной модели значение всех метрик эффективности классификации на тестовой и обучающей выборках. Нужно использовать следующие метрики: accuracy, precision, recall, f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузите данные о вероятности развития сердечного приступа, прилагающийся к этой работе (heart.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "\n",
       "   caa  thall  output  \n",
       "0    0      1       1  \n",
       "1    0      2       1  \n",
       "2    0      2       1  \n",
       "3    0      2       1  \n",
       "4    0      2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/heart.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Обучите на этих данных простую модель логистической регрессии и выведите метрику точности (accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('output', axis=1)\n",
    "y = data['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5175499644256842"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Разделите датасет на две части - первую половину используйте для обучения, а вторую - для оценки точности. Сравните значения метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = X[:200], y[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 13), (200,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((103, 13), (103,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test, y_test = X[200:], y[200:]\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45405804018236195"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.75194431,  0.1589634 ,  0.45760619,  0.6185906 , -0.20536379,\n",
       "        0.63463611,  0.34723006,  0.31155265,  0.4546555 ,  0.6752418 ,\n",
       "        0.73309023,  0.14842541,  0.56768794,  0.55630577,  0.44877022,\n",
       "        0.26813972,  0.73318975,  0.10733601,  0.21077554,  0.44121948,\n",
       "        0.01226233, -0.07190108,  0.8527078 ,  0.00574668,  0.21386137,\n",
       "        0.33361744,  0.41562629,  0.44133546,  0.95184152,  0.61487406,\n",
       "        1.0651674 ,  0.23974811,  0.39561276,  0.22404809,  0.14463121,\n",
       "        0.53857414,  0.54039987,  0.37441532,  0.49652804,  0.59427433,\n",
       "        0.40497086,  0.88486639,  0.45384374,  0.33911121,  0.40688837,\n",
       "        0.6005157 ,  0.25104764,  0.70110343,  0.79235655,  0.38460263,\n",
       "       -0.13155312,  0.21930841,  0.39190055,  0.35642161,  1.05394538,\n",
       "        0.3062811 ,  0.03386762,  0.45263146,  0.73724523,  0.57409542,\n",
       "        0.55453266,  0.8048266 ,  0.15974414,  0.53138964,  0.53636692,\n",
       "        0.61174202,  0.49997098,  0.63558869,  0.0727705 ,  0.26428147,\n",
       "        0.56682765,  0.68170541,  0.59395474,  0.6838095 ,  0.40626029,\n",
       "        0.52989096,  0.36097258,  0.8156664 ,  0.81227857,  0.17846966,\n",
       "        0.5854293 ,  0.87827927,  0.78798229,  0.82580133,  0.31739102,\n",
       "        0.21601046,  0.9641996 ,  0.8475039 ,  0.18941333,  0.5263364 ,\n",
       "        0.73561087,  0.18991621,  0.42098122,  0.79235083,  0.51581958,\n",
       "        0.0113101 ,  0.87671559,  0.50776324,  0.71249151,  0.84682237,\n",
       "        0.19458025,  0.4292016 ,  0.92737323])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Разделите датасет на две части случайным образом. Повторите анализ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((242, 13), (242,), (61, 13), (61,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = int(X.shape[0] * 0.8)\n",
    "\n",
    "x_train, y_train, x_test, y_test = X[:N], y[:N], X[N:], y[N:]\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_fn = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_fn.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5452486098240782"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_fn.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_fn.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Разделите датасет с помощью библиотечной функции. Повторите анализ несколько раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_fn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17647891,  0.82510779,  0.58514645,  0.1056269 ,  0.32574318,\n",
       "        0.15210994,  0.82318605,  0.57018772,  0.70103733,  0.59180367,\n",
       "        0.62588345,  0.85692247,  0.49847587,  0.6230463 ,  0.23663993,\n",
       "        0.2352642 ,  0.91772138,  0.36957632, -0.02820548,  0.52333318,\n",
       "        0.59945248,  0.80860817,  0.75258012,  0.64590009,  0.7665215 ,\n",
       "        1.07262536,  0.30056898, -0.00319354,  0.60502925,  0.77703391,\n",
       "        1.10967803,  0.70340858,  0.36648756,  1.17299956,  0.68591857,\n",
       "        0.87238944,  0.35397888,  0.29997517,  0.960665  , -0.05687151,\n",
       "        0.21038429,  0.2654329 ,  0.00298914,  1.25103845,  0.90200896,\n",
       "        0.6245337 ,  0.60636119,  1.10160036,  0.72509245,  1.03859804,\n",
       "       -0.11098893,  0.9544871 ,  0.64364698,  0.81414189,  0.55850174,\n",
       "        0.86443662,  1.20780829,  0.49474224,  0.73065513, -0.08184096,\n",
       "        0.2660605 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_fn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5254123430004067"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_fn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4558675261000401"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_fn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Постройте матрицу классификации и отчет о классификации для обученной модели для обучающей и тестовой выборок. Проинтерпретируйте полученные значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lr_model.predict(x_test)\n",
    "y_train_pred = lr_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 22,  89],\n",
       "       [ 31, 100]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_binary = (y_train_pred >= 0.5).astype(int)\n",
    "confusion_matrix(y_train, y_train_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 14],\n",
       "       [14, 20]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_binary = (y_test_pred >= 0.5).astype(int)\n",
    "confusion_matrix(y_test, y_test_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.48      0.48        27\n",
      "           1       0.59      0.59      0.59        34\n",
      "\n",
      "    accuracy                           0.54        61\n",
      "   macro avg       0.53      0.53      0.53        61\n",
      "weighted avg       0.54      0.54      0.54        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Подсчитайте для построенной модели значение всех метрик эффективности классификации на тестовой и обучающей выборках. Нужно использовать следующие метрики: accuracy, precision, recall, f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.540984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.529101</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.763359</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Train      Test\n",
       "Accuracy   0.504132  0.540984\n",
       "Precision  0.529101  0.588235\n",
       "Recall     0.763359  0.588235\n",
       "F1         0.625000  0.588235"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame({\n",
    "    \"Train\": [\n",
    "        accuracy_score(y_train, y_train_pred_binary),\n",
    "        precision_score(y_train, y_train_pred_binary),\n",
    "        recall_score(y_train, y_train_pred_binary),\n",
    "        f1_score(y_train, y_train_pred_binary),\n",
    "    ],\n",
    "    \"Test\": [\n",
    "        accuracy_score(y_test, y_test_pred_binary),\n",
    "        precision_score(y_test, y_test_pred_binary),\n",
    "        recall_score(y_test, y_test_pred_binary),\n",
    "        f1_score(y_test, y_test_pred_binary),\n",
    "    ],\n",
    "}, index = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задания для самостоятельного выполнения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Повторите анализ для других видов моделей. Используйте 5-10 разных классов моделей. Подсчитывайте только метрики на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models_classification(X_train, X_test, y_train, y_test):\n",
    "    models = {\n",
    "        \"Логистическая регрессия\": LogisticRegression(max_iter=1000),\n",
    "        \"Метод опорных векторов (линейное ядро)\": SVC(kernel='linear', probability=True),\n",
    "        \"Метод опорных векторов (гауссовое ядро)\": SVC(kernel='rbf', probability=True),\n",
    "        \"Метод ближайших соседей\": KNeighborsClassifier(),\n",
    "        \"Дерево решений\": DecisionTreeClassifier(),\n",
    "        \"Случайный лес\": RandomForestClassifier(),\n",
    "        \"Градиентный бустинг\": GradientBoostingClassifier(),\n",
    "        \"Беггинг\": BaggingClassifier(),\n",
    "        \"Многослойный перцептрон\": MLPClassifier(max_iter=1000)\n",
    "    }\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test) # Берём вероятность положительного класса\n",
    "        \n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class=\"ovr\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "        cv_score = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_weighted').mean()\n",
    "\n",
    "        print(f\"{model_name}:\")\n",
    "        print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  F1-score: {f1:.4f}\")\n",
    "        print(f\"  Кросс-валидация (F1-score): {cv_score:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия:\n",
      "  ROC-AUC: 1.0000\n",
      "  Accuracy: 1.0000\n",
      "  F1-score: 1.0000\n",
      "  Кросс-валидация (F1-score): 0.9657\n",
      "\n",
      "Метод опорных векторов (линейное ядро):\n",
      "  ROC-AUC: 1.0000\n",
      "  Accuracy: 1.0000\n",
      "  F1-score: 1.0000\n",
      "  Кросс-валидация (F1-score): 0.9574\n",
      "\n",
      "Метод опорных векторов (гауссовое ядро):\n",
      "  ROC-AUC: 1.0000\n",
      "  Accuracy: 1.0000\n",
      "  F1-score: 1.0000\n",
      "  Кросс-валидация (F1-score): 0.9477\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод ближайших соседей:\n",
      "  ROC-AUC: 1.0000\n",
      "  Accuracy: 1.0000\n",
      "  F1-score: 1.0000\n",
      "  Кросс-валидация (F1-score): 0.9393\n",
      "\n",
      "Дерево решений:\n",
      "  ROC-AUC: 1.0000\n",
      "  Accuracy: 1.0000\n",
      "  F1-score: 1.0000\n",
      "  Кросс-валидация (F1-score): 0.9410\n",
      "\n",
      "Случайный лес:\n",
      "  ROC-AUC: 1.0000\n",
      "  Accuracy: 1.0000\n",
      "  F1-score: 1.0000\n",
      "  Кросс-валидация (F1-score): 0.9493\n",
      "\n",
      "Градиентный бустинг:\n",
      "  ROC-AUC: 1.0000\n",
      "  Accuracy: 1.0000\n",
      "  F1-score: 1.0000\n",
      "  Кросс-валидация (F1-score): 0.9410\n",
      "\n",
      "Беггинг:\n",
      "  ROC-AUC: 1.0000\n",
      "  Accuracy: 1.0000\n",
      "  F1-score: 1.0000\n",
      "  Кросс-валидация (F1-score): 0.9331\n",
      "\n",
      "Многослойный перцептрон:\n",
      "  ROC-AUC: 1.0000\n",
      "  Accuracy: 1.0000\n",
      "  F1-score: 1.0000\n",
      "  Кросс-валидация (F1-score): 0.9657\n",
      "\n",
      "Classification Results:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "classification_results = train_and_evaluate_models_classification(X_train, X_test, y_train, y_test)\n",
    "print(\"Classification Results:\")\n",
    "print(classification_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Повторите анализ для другого датасета по вашему выбору. Используйте несколько моделей для сравнения. Используйте датасет для множественной классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия:\n",
      "  ROC-AUC: 1.0000\n",
      "  Accuracy: 0.9722\n",
      "  F1-score: 0.9722\n",
      "  Кросс-валидация (F1-score): 0.9427\n",
      "\n",
      "Метод опорных векторов (линейное ядро):\n",
      "  ROC-AUC: 1.0000\n",
      "  Accuracy: 1.0000\n",
      "  F1-score: 1.0000\n",
      "  Кросс-валидация (F1-score): 0.9426\n",
      "\n",
      "Метод опорных векторов (гауссовое ядро):\n",
      "  ROC-AUC: 0.8439\n",
      "  Accuracy: 0.8056\n",
      "  F1-score: 0.8024\n",
      "  Кросс-валидация (F1-score): 0.6027\n",
      "\n",
      "Метод ближайших соседей:\n",
      "  ROC-AUC: 0.8828\n",
      "  Accuracy: 0.7222\n",
      "  F1-score: 0.7222\n",
      "  Кросс-валидация (F1-score): 0.6539\n",
      "\n",
      "Дерево решений:\n",
      "  ROC-AUC: 0.9521\n",
      "  Accuracy: 0.9444\n",
      "  F1-score: 0.9440\n",
      "  Кросс-валидация (F1-score): 0.9143\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/egorprozorov/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Случайный лес:\n",
      "  ROC-AUC: 1.0000\n",
      "  Accuracy: 1.0000\n",
      "  F1-score: 1.0000\n",
      "  Кросс-валидация (F1-score): 0.9713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.2, random_state=42)\n",
    "classification_results_wine = train_and_evaluate_models_classification(X_train, X_test, y_train, y_test)\n",
    "print(\"\\nMulti-class Classification Results (Wine Dataset):\")\n",
    "print(classification_results_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Повторите анализ для датасета, предназначенного для решения задачи регрессии. Используйте все метрики качества регрессии, изученные на лекции. Постройте 5 - 10 разных моделей регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    models = {\n",
    "        \"Линейная регрессия\": LinearRegression(),\n",
    "        \"Гребневая регрессия\": Ridge(),\n",
    "        \"Лассо регрессия\": Lasso(),\n",
    "        \"ElasticNet регрессия\": ElasticNet(),\n",
    "        \"Метод опорных векторов (без ядра)\": SVR(kernel='linear'),\n",
    "        \"Метод опорных векторов (гауссовое ядро)\": SVR(kernel='rbf'),\n",
    "        \"Метод опорных векторов (полиномиальное ядро)\": SVR(kernel='poly'),\n",
    "        \"Метод ближайших соседей\": KNeighborsRegressor(),\n",
    "        \"Многослойный перцептрон\": MLPRegressor(max_iter=1000),\n",
    "        \"Дерево решений\": DecisionTreeRegressor(),\n",
    "        \"Случайный лес\": RandomForestRegressor(),\n",
    "        \"Беггинг\": BaggingRegressor()\n",
    "    }\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Метрики\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # Кросс-валидация - промежуточный этап оценки модели\n",
    "        cv_score = cross_val_score(model, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "\n",
    "        # Выводим результаты\n",
    "        print(f\"{model_name}:\")\n",
    "        print(f\"  R²: {r2:.4f}\")\n",
    "        print(f\"  MAE: {mae:.4f}\")\n",
    "        print(f\"  MSE: {mse:.4f}\")\n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  Кросс-валидация: {cv_score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Линейная регрессия:\n",
      "  R²: 0.4526\n",
      "  MAE: 42.7941\n",
      "  MSE: 2900.1936\n",
      "  RMSE: 53.8534\n",
      "  Кросс-валидация: 0.4493\n",
      "\n",
      "Гребневая регрессия:\n",
      "  R²: 0.4192\n",
      "  MAE: 46.1389\n",
      "  MSE: 3077.4159\n",
      "  RMSE: 55.4745\n",
      "  Кросс-валидация: 0.3802\n",
      "\n",
      "Лассо регрессия:\n",
      "  R²: 0.3576\n",
      "  MAE: 49.7303\n",
      "  MSE: 3403.5757\n",
      "  RMSE: 58.3402\n",
      "  Кросс-валидация: 0.3238\n",
      "\n",
      "ElasticNet регрессия:\n",
      "  R²: -0.0025\n",
      "  MAE: 63.7059\n",
      "  MSE: 5311.2128\n",
      "  RMSE: 72.8781\n",
      "  Кросс-валидация: -0.0216\n",
      "\n",
      "Метод опорных векторов (без ядра):\n",
      "  R²: 0.0203\n",
      "  MAE: 61.9045\n",
      "  MSE: 5190.3877\n",
      "  RMSE: 72.0443\n",
      "  Кросс-валидация: -0.0263\n",
      "\n",
      "Метод опорных векторов (гауссовое ядро):\n",
      "  R²: 0.1821\n",
      "  MAE: 56.0237\n",
      "  MSE: 4333.2860\n",
      "  RMSE: 65.8277\n",
      "  Кросс-валидация: 0.1122\n",
      "\n",
      "Метод опорных векторов (полиномиальное ядро):\n",
      "  R²: 0.2822\n",
      "  MAE: 51.6617\n",
      "  MSE: 3803.0441\n",
      "  RMSE: 61.6688\n",
      "  Кросс-валидация: 0.1794\n",
      "\n",
      "Метод ближайших соседей:\n",
      "  R²: 0.4302\n",
      "  MAE: 42.7708\n",
      "  MSE: 3019.0755\n",
      "  RMSE: 54.9461\n",
      "  Кросс-валидация: 0.3172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Многослойный перцептрон:\n",
      "  R²: 0.3925\n",
      "  MAE: 47.5081\n",
      "  MSE: 3218.4649\n",
      "  RMSE: 56.7315\n",
      "  Кросс-валидация: 0.3779\n",
      "\n",
      "Дерево решений:\n",
      "  R²: 0.0602\n",
      "  MAE: 54.2809\n",
      "  MSE: 4979.0449\n",
      "  RMSE: 70.5623\n",
      "  Кросс-валидация: -0.0931\n",
      "\n",
      "Случайный лес:\n",
      "  R²: 0.4218\n",
      "  MAE: 44.5292\n",
      "  MSE: 3063.2860\n",
      "  RMSE: 55.3470\n",
      "  Кросс-валидация: 0.3923\n",
      "\n",
      "Беггинг:\n",
      "  R²: 0.3405\n",
      "  MAE: 48.1169\n",
      "  MSE: 3494.2620\n",
      "  RMSE: 59.1123\n",
      "  Кросс-валидация: 0.3702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Почему для анализа модели нужно применять несколько метрик эффективности?**\n",
    "\n",
    "Для более точной и комплексной оценки модели важно учитывать несколько метрик эффективности, потому что каждая метрика отражает разные аспекты работы модели. Например, точность может быть высокой, но при этом модель может не учитывать важные классы или проявлять сильные ошибки для некоторых типов данных. Использование нескольких метрик помогает избежать искажений, улучшает понимание модели и её слабых мест.\n",
    "\n",
    "**2. Зачем для анализа качества модели делить датасет на обучающую и тренировочную выборки?**\n",
    "\n",
    "Деление датасета на обучающую и тестовую выборки позволяет:\n",
    "- Избежать переобучения (overfitting) — когда модель слишком хорошо подгоняется под данные, на которых обучалась, и не может обобщать на новых данных.\n",
    "- Проверить обобщающую способность модели — насколько хорошо модель будет работать на данных, которые она не видела раньше.\n",
    "- Получить объективную оценку качества модели, которая не будет завышенной из-за использования тех же данных для обучения и тестирования.\n",
    "\n",
    "**3. В чем особенность и область применения каждой метрики качества?**\n",
    "\n",
    "- **Точность (Accuracy)**: Применяется, когда важен общий процент правильных предсказаний по всем классам. Не подходит для дисбалансированных классов.\n",
    "- **Точность (Precision)**: Используется, когда важно минимизировать ложные срабатывания (например, в задаче обнаружения спама). Хорошо подходит для работы с редкими событиями.\n",
    "- **Полнота (Recall)**: Используется, когда важно минимизировать ложные пропуски (например, в задаче медицинского диагностики, где важно не пропустить больного пациента).\n",
    "- **F1-меры**: Комбинированная метрика для учета как точности, так и полноты, используется, когда нужно сбалансировать оба аспекта.\n",
    "- **ROC-AUC (Area Under the Curve)**: Используется для оценки модели на дисбалансированных данных. AUC измеряет способность модели различать классы.\n",
    "- **MSE (Mean Squared Error)**: Используется в регрессии, когда важна минимизация ошибок предсказания.\n",
    "- **MAE (Mean Absolute Error)**: Применяется, когда важно минимизировать абсолютную ошибку (не учитывая квадраты ошибок), например, для предсказания времени.\n",
    "\n",
    "**4. Для каждой метрики классификации и регрессии придумайте пример, в котором данная метрика будет определяющей для выбора наилучшей модели.**\n",
    "\n",
    "- **Точность (Accuracy)**: Для задачи классификации изображений, где важно, чтобы общая точность модели была как можно выше, например, для распознавания лиц на фото.\n",
    "- **Точность (Precision)**: В задаче классификации спама, когда важно минимизировать количество ложных срабатываний.\n",
    "- **Полнота (Recall)**: В медицинской диагностике для выявления заболеваний, где важно, чтобы модель не пропускала больных людей (например, для рака).\n",
    "- **F1-меры**: В задачах, где нужно сбалансировать точность и полноту, например, для классификации редких событий в кредитных карточках.\n",
    "- **ROC-AUC**: В задаче классификации заболеваний, где классы сильно дисбалансированы (например, больных и здоровых).\n",
    "- **MSE (Mean Squared Error)**: В задаче прогнозирования стоимости недвижимости, где важна точность прогноза.\n",
    "- **MAE (Mean Absolute Error)**: В задаче прогнозирования температуры, где важна минимизация абсолютной ошибки, независимо от её направления.\n",
    "\n",
    "**5. В каких случаях нельзя делить выборку случайным образом?**\n",
    "\n",
    "Делить выборку случайным образом не следует в следующих случаях:\n",
    "- **Временные ряды**: Если данные имеют зависимость от времени (например, экономические показатели), случайное деление может нарушить временную последовательность.\n",
    "- **Группировка данных**: Когда данные имеют определенные группы или кластеризацию, случайное деление может привести к неравномерному распределению этих групп между обучающей и тестовой выборками.\n",
    "- **Дисбаланс классов**: Когда один из классов сильно преобладает, случайное разделение может привести к тому, что тестовая выборка не будет отражать реальное распределение данных. В таких случаях следует использовать методы стратификации.\n",
    "\n",
    "**6. Зачем нужен и как использовать отчет о классификации?**\n",
    "\n",
    "Отчет о классификации (classification report) в sklearn предоставляет сводную информацию о метриках точности, полноты, F1-меры и поддержке для каждого класса. Он полезен для:\n",
    "- Оценки качества модели по различным классам, особенно когда классы дисбалансированы.\n",
    "- Сравнения работы модели по различным меткам или категориям.\n",
    "- Быстрой диагностики проблем модели, например, если модель плохо работает на одном из классов, несмотря на высокую общую точность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
