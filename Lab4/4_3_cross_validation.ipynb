{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кросс-валидация\n",
    "\n",
    "## Цель работы\n",
    "Познакомиться с основными типами разбиений данных при осуществлении кросс-валидации с использованием библиотеки sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задания для выполнения\n",
    "1. Загрузите датасет ирисы Фишера из библиотеки sklearn.datasets.\n",
    "2. Сделайте hold-out разбиение данных. Для этого разделите данные на обучающую и валидационную выборки и выведите на экран соответствующие индексы разбиения.\n",
    "3. Теперь сделайте разбиение перемешанных данных, зафиксировав воспроизводимость выбора данных после перемешивания, указав значение параметра random_state=42 и выведите на экран соответствующие индексы разбиения.\n",
    "4. Обучите модель логистической регрессии на обучающих данных. Выведите значения коэффициентов модели, полученных в результате обучения. Сделайте предсказание на тестовом наборе признаков. Выведите значение метрик accuracy и f1-score.\n",
    "5. Разделите данные на обучающую и валидационную выборки по новому в соотношении 75-25. Обучите модель на этих данных, выведите значения получившихся коэффициентов модели. Выведите значения метрик и сравните их со значениями из предыдущего пункта. Сделайте вывод о том, влияет ли способ разбиения на результат.\n",
    "6. Теперь сделайте k-блочную перекрёстную проверку модели (кросс-валидацию). Сравните полученные метрики с метриками, которые были при hold-out разбиении.\n",
    "7. Теперь сделайте ту же самую перекрёстную проверку модели, используя библиотечную функцию cross_val_score. Убедитесь, что получится тот же результат.\n",
    "8. Теперь сделайте k-блочную перекрёстную проверку модели (кросс-валидацию) со стратификацией. Проделайте всё тоже самое, что и в предыдущем пункте.\n",
    "9. Теперь сделайте перекрёстную проверку, изпользуя leave-one-out разбиение. Проделайте всё тоже самое, что и в предыдущем пункте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузите датасет ирисы Фишера из библиотеки sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Сделайте hold-out разбиение данных. Для этого разделите данные на обучающую и валидационную выборки и выведите на экран соответствующие индексы разбиения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "5                5.4               3.9                1.7               0.4   \n",
       "6                4.6               3.4                1.4               0.3   \n",
       "7                5.0               3.4                1.5               0.2   \n",
       "8                4.4               2.9                1.4               0.2   \n",
       "9                4.9               3.1                1.5               0.1   \n",
       "\n",
       "         class  \n",
       "0  Iris-setosa  \n",
       "1  Iris-setosa  \n",
       "2  Iris-setosa  \n",
       "3  Iris-setosa  \n",
       "4  Iris-setosa  \n",
       "5  Iris-setosa  \n",
       "6  Iris-setosa  \n",
       "7  Iris-setosa  \n",
       "8  Iris-setosa  \n",
       "9  Iris-setosa  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "name_map = {0: 'Iris-setosa', 1: 'Iris-versicolor', 2:'Iris-virginica'}\n",
    "iris_data['class'] = [name_map[k] for k in iris['target']]\n",
    "iris_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Теперь сделайте разбиение перемешанных данных, зафиксировав воспроизводимость выбора данных после перемешивания, указав значение параметра random_state=42 и выведите на экран соответствующие индексы разбиения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4), (120,), (30,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Обучите модель логистической регрессии на обучающих данных. Выведите значения коэффициентов модели, полученных в результате обучения. Сделайте предсказание на тестовом наборе признаков. Выведите значение метрик accuracy и f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression(solver='liblinear') # Используем liblinear как регулязатор в нашей задачи\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3711229 ,  1.409712  , -2.15210117, -0.95474179],\n",
       "       [ 0.49400451, -1.58897112,  0.43717015, -1.11187838],\n",
       "       [-1.55895271, -1.58893375,  2.39874554,  2.15556209]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Разделите данные на обучающую и валидационную выборки по новому в соотношении 75-25. Обучите модель на этих данных, выведите значения получившихся коэффициентов модели. Выведите значения метрик и сравните их со значениями из предыдущего пункта. Сделайте вывод о том, влияет ли способ разбиения на результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_fn = LogisticRegression(solver='liblinear') # Используем liblinear как регулязатор в нашей задачи\n",
    "lr_model_fn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37199402,  1.3721129 , -2.12209543, -0.93577108],\n",
       "       [ 0.46579126, -1.55972584,  0.41868466, -1.08288284],\n",
       "       [-1.55311025, -1.5151226 ,  2.36636048,  2.1109172 ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_fn.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model_fn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Теперь сделайте k-блочную перекрёстную проверку модели (кросс-валидацию). Сравните полученные метрики с метриками, которые были при hold-out разбиении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold,LeaveOneOut, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=3, random_state=15, shuffle=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits = 3,shuffle=True, random_state=15)\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Длинна train: 100, Длинна test: 50\n",
      "Train: index=[  1   2   3   4   7  10  14  15  16  17  18  19  22  23  24  26  28  29\n",
      "  32  33  34  35  37  38  39  40  41  42  43  44  45  46  49  50  51  52\n",
      "  53  54  56  60  62  63  64  65  66  68  69  70  73  75  76  77  79  80\n",
      "  81  82  83  85  87  88  91  92  93  94  96  99 101 102 104 105 106 107\n",
      " 108 110 111 113 114 117 118 119 120 121 123 125 128 131 132 133 134 135\n",
      " 136 137 139 140 141 142 144 145 146 147]\n",
      " Test:  index=[  0   5   6   8   9  11  12  13  20  21  25  27  30  31  36  47  48  55\n",
      "  57  58  59  61  67  71  72  74  78  84  86  89  90  95  97  98 100 103\n",
      " 109 112 115 116 122 124 126 127 129 130 138 143 148 149]\n",
      "Fold 2: Длинна train: 100, Длинна test: 50\n",
      "Train: index=[  0   1   4   5   6   7   8   9  10  11  12  13  15  17  19  20  21  22\n",
      "  23  24  25  26  27  28  30  31  34  36  37  39  40  41  42  44  47  48\n",
      "  50  53  55  56  57  58  59  60  61  62  63  65  66  67  70  71  72  74\n",
      "  75  78  79  84  85  86  89  90  95  96  97  98  99 100 101 102 103 104\n",
      " 105 107 109 112 114 115 116 118 119 121 122 124 125 126 127 128 129 130\n",
      " 131 133 134 138 140 143 145 146 148 149]\n",
      " Test:  index=[  2   3  14  16  18  29  32  33  35  38  43  45  46  49  51  52  54  64\n",
      "  68  69  73  76  77  80  81  82  83  87  88  91  92  93  94 106 108 110\n",
      " 111 113 117 120 123 132 135 136 137 139 141 142 144 147]\n",
      "Fold 3: Длинна train: 100, Длинна test: 50\n",
      "Train: index=[  0   2   3   5   6   8   9  11  12  13  14  16  18  20  21  25  27  29\n",
      "  30  31  32  33  35  36  38  43  45  46  47  48  49  51  52  54  55  57\n",
      "  58  59  61  64  67  68  69  71  72  73  74  76  77  78  80  81  82  83\n",
      "  84  86  87  88  89  90  91  92  93  94  95  97  98 100 103 106 108 109\n",
      " 110 111 112 113 115 116 117 120 122 123 124 126 127 129 130 132 135 136\n",
      " 137 138 139 141 142 143 144 147 148 149]\n",
      " Test:  index=[  1   4   7  10  15  17  19  22  23  24  26  28  34  37  39  40  41  42\n",
      "  44  50  53  56  60  62  63  65  66  70  75  79  85  96  99 101 102 104\n",
      " 105 107 114 118 119 121 125 128 131 133 134 140 145 146]\n"
     ]
    }
   ],
   "source": [
    "for i, (train_index, test_index) in enumerate(kf.split(y)):\n",
    "    print(\"Fold {}: Длинна train: {}, Длинна test: {}\".format(i+1, len(train_index), len(test_index)))\n",
    "    print('Train: index={}\\n Test:  index={}'.format(train_index, test_index))\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_accuracy = []\n",
    "metrics_f1 = []\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "for i, (train_index, test_index) in enumerate(kf.split(y)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    metrics_accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    metrics_f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значения метрики accuracy: [0.96, 0.96, 0.9] \n",
      "Значения метрики f1: [0.9595588235294118, 0.9629629629629629, 0.890652557319224]\n"
     ]
    }
   ],
   "source": [
    "print('Значения метрики accuracy: {} \\nЗначения метрики f1: {}'.format(metrics_accuracy, metrics_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее по кросс-валидации:  0.9377247812705329\n"
     ]
    }
   ],
   "source": [
    "print(\"Среднее по кросс-валидации: \", np.array(metrics_f1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Теперь сделайте ту же самую перекрёстную проверку модели, используя библиотечную функцию cross_val_score. Убедитесь, что получится тот же результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кросс-валидация:  [0.96 0.96 0.9 ]\n",
      "Среднее по кросс-валидации:  0.94\n",
      "Дисперсия по кросс-валидации:  0.028284271247461874\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_val_score(model,                  # модель\n",
    "                             X,                      # матрица признаков\n",
    "                             y,                      # вектор цели\n",
    "                             cv = kf,                # тип разбиения (можно указать просто число фолдов cv = 3)\n",
    "                             scoring = 'accuracy',   # метрика\n",
    "                             n_jobs=-1)              # используются все ядра CPU\n",
    "\n",
    "print(\"Кросс-валидация: \", cv_results)\n",
    "print(\"Среднее по кросс-валидации: \", cv_results.mean())\n",
    "print(\"Дисперсия по кросс-валидации: \", cv_results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Теперь сделайте k-блочную перекрёстную проверку модели (кросс-валидацию) со стратификацией. Проделайте всё тоже самое, что и в предыдущем пункте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3,shuffle=True, random_state=15)\n",
    "skf.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кросс-валидация со стратификацией:  [1.   1.   0.92]\n",
      "Среднее по кросс-валидации со стратификацией:  0.9733333333333333\n",
      "Дисперсия по кросс-валидации со стратификацией:  0.03771236166328251\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_val_score(model,                  # модель\n",
    "                             X,                      # матрица признаков\n",
    "                             y,                      # вектор цели\n",
    "                             cv = skf,                # тип разбиения (можно указать просто число фолдов cv = 3)\n",
    "                             scoring = 'accuracy',   # метрика\n",
    "                             n_jobs=-1)              # используются все ядра CPU\n",
    "\n",
    "print(\"Кросс-валидация со стратификацией: \", cv_results)\n",
    "print(\"Среднее по кросс-валидации со стратификацией: \", cv_results.mean())\n",
    "print(\"Дисперсия по кросс-валидации со стратификацией: \", cv_results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Теперь сделайте перекрёстную проверку, изпользуя leave-one-out разбиение. Проделайте всё тоже самое, что и в предыдущем пункте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кросс-валидация с leave-one-out разбиением:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "Среднее по кросс-валидации с leave-one-out разбиением:  0.9533333333333334\n",
      "Дисперсия по кросс-валидации с leave-one-out разбиением:  0.21092389359408498\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_val_score(model,                  # модель\n",
    "                             X,                      # матрица признаков\n",
    "                             y,                      # вектор цели\n",
    "                             cv = loo,                # тип разбиения (можно указать просто число фолдов cv = 3)\n",
    "                             scoring = 'accuracy',   # метрика\n",
    "                             n_jobs=-1)              # используются все ядра CPU\n",
    "\n",
    "print(\"Кросс-валидация с leave-one-out разбиением: \", cv_results)\n",
    "print(\"Среднее по кросс-валидации с leave-one-out разбиением: \", cv_results.mean())\n",
    "print(\"Дисперсия по кросс-валидации с leave-one-out разбиением: \", cv_results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Зачем нужно применять кросс-валидацию?**\n",
    "\n",
    "Кросс-валидация используется для оценки обобщающей способности модели на новых данных. Это помогает избежать переобучения и недообучения, давая более надежную и объективную оценку качества модели. Кросс-валидация позволяет проверять модель на разных подмножествах данных, что способствует более точному представлению о том, как она будет работать на реальных данных.\n",
    "\n",
    "**2. В чём заключается процесс кросс-валидации?**\n",
    "\n",
    "Процесс кросс-валидации заключается в разделении данных на несколько подмножеств (обычно K частей), затем модель обучается на всех частях данных, кроме одной, которая используется для тестирования. Этот процесс повторяется несколько раз, каждый раз с другим подмножеством в качестве тестовой выборки. В результате модель тестируется на различных частях данных, что помогает получить среднюю оценку её производительности.\n",
    "\n",
    "**3. В чем достоинства и недостатки каждого метода кросс-валидации?**\n",
    "\n",
    "- **K-fold кросс-валидация**:\n",
    "  - *Достоинства*: Эффективное использование всех данных для тренировки и тестирования, уменьшает вероятность переобучения.\n",
    "  - *Недостатки*: Затратно по времени, особенно при большом числе фолдов и объемных данных.\n",
    "\n",
    "- **Leave-One-Out (LOO) кросс-валидация**:\n",
    "  - *Достоинства*: Каждое наблюдение используется для тестирования, что позволяет получить максимально точную оценку.\n",
    "  - *Недостатки*: Очень высокие вычислительные затраты, особенно при большом количестве данных.\n",
    "\n",
    "- **Stratified K-fold**:\n",
    "  - *Достоинства*: Учитывает баланс классов, что важно при несбалансированных данных.\n",
    "  - *Недостатки*: Более сложен в реализации и несколько менее эффективен, чем обычный K-fold.\n",
    "\n",
    "**4. Какой метод кросс-валидации можно применять на данных с большим дисбалансом классов?**\n",
    "\n",
    "Для данных с дисбалансом классов рекомендуется использовать **Stratified K-fold** кросс-валидацию. Этот метод гарантирует, что каждый фолд будет иметь пропорции классов, аналогичные пропорциям в исходном наборе данных, что предотвращает доминирование одного класса в обучающей или тестовой выборке.\n",
    "\n",
    "**5. Можно ли бороться с недообучением при помощи кросс-валидации? А с переобучением?**\n",
    "\n",
    "- **Недообучение**: Кросс-валидация сама по себе не помогает бороться с недообучением. Для борьбы с недообучением нужно настроить модель, улучшить её архитектуру или использовать более сложные алгоритмы.\n",
    "\n",
    "- **Переобучение**: Кросс-валидация помогает бороться с переобучением, так как она оценивает модель на разных частях данных, что снижает риск, что модель будет слишком подгоняться под конкретный набор данных. Она позволяет выбрать модель с лучшими обобщающими способностями.\n",
    "\n",
    "**6. Какие основные типы разбиений данных используются при кросс-валидации?**\n",
    "\n",
    "- **K-fold**: Данные делятся на K частей (фолдов). Каждый фолд поочередно используется как тестовая выборка, а оставшиеся K-1 части используются для обучения.\n",
    "- **Leave-One-Out (LOO)**: Каждый пример в датасете используется как тестовая выборка, а остальные - для обучения. Это крайний случай K-fold, где K равно количеству объектов в датасете.\n",
    "- **Stratified K-fold**: Деление данных с учетом соотношения классов, что особенно полезно для задач с несбалансированными классами.\n",
    "- **Shuffle Split**: Данные случайным образом делятся на тренировочные и тестовые наборы, обычно несколько раз с разными разделениями.\n",
    "\n",
    "**7. Какой тип кросс-валидации можно применять, если нужно сделать очень большое количество проходов?**\n",
    "\n",
    "Для очень большого количества проходов рекомендуется использовать **Shuffle Split** или **Repeated K-fold**. Эти методы позволяют проводить несколько повторных разбиений данных, что дает более точные оценки без необходимости выполнять дорогие операции с большим количеством фолдов. Такой подход может быть менее затратным по времени, чем Leave-One-Out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
